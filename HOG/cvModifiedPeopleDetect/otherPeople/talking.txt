>
> > This is what I am working on right now. Im getting training data today and
>
> > hopefully I'll have some results during the weekend, but what I was going to
do
>
> > is to use CvSVM::train and then CvSMV::get_support_vector* to get that
floating
>
> > point array to feed it into HOG::setSvmDetector() and then call
>
> > detect_multiScale. I dont know if its gonna work but I'll keep you posted.
If
>
> > you figure out what is the problem please let me know.
>
> >
>
Hi,
yes I'm calling hog->compute() with default HOG parameter settings (
hog.winSize.width = 64; hog.winSize.height = 128; hog.cellSize.width = 8 =
hog.cellSize.height; hog.blockSize.width = 16; hog.blockStride.width = 8;
winStride = Size(8, 8); padding = Size(32, 32); etc. but for training, use
trainingPadding = Size(0,0) ), some excerpt of my code that could interest you:
std::vector<float>* calculateDescriptor(Mat img) {
vector<float>* descriptorVector = new std::vector<float>();
vector<Point> locations;
// Calculate the HOG from the image and return them in the descriptor
vector
hog.compute(img, *descriptorVector, winStride, trainingPadding,
locations);
printf("Descriptor vector size: %u", descriptorVector->size());
return descriptorVector;
}
My descriptor vectors returned when training with these parameters are all of
size 3780, the way it should be...
I assume you have different HOG parameter values (e.g. a larger input image than
64x128 or padding not 0 for training?)

Greetings,

Jan Hendriks





________________________________
From: Rufat Mammadyarov <rufus_230590@...>
To: J H <dahoc3150@...>; Long Long Yu <mr.fantastico@...>
Cc: OpenCV@yahoogroups.com
Sent: Tue, July 27, 2010 6:50:42 PM
Subject: Re: [OpenCV] Re: HOGDescriptor::getDefaultPeopleDetector()


I understand that you already passed the stage of computing hog features for
each image.
I use compute() function of HogDescriptor and its not like it doesn't work but
the size of the descriptor turns out to be really large. My recent attempt got
me the size of descriptor for one image of 12 million. It doesn't sound right.
Did you get something like that? If not what were your arguments for compute
function and what was the size of descriptor you were getting?
Once I'm done with that I will start on actually training SVM and them maybe
will be able to contribute to he discussion.

________________________________
From: J H <dahoc3150@...>
To: Long Long Yu <mr.fantastico@...>
Cc: OpenCV@yahoogroups.com
Sent: Mon, July 26, 2010 5:38:14 AM
Subject: [OpenCV] Re: HOGDescriptor::getDefaultPeopleDetector()

Hi,
thanks again, but I still don't know how the getDefaultPeopleDescriptor() vector


is generated (is it generated by a SVM at all?) and how to calculate a similar
vector from my own training data set, and I'm running out of ideas...
Can anybody tell me how to generate that vector?
It seems there are some serious differences between the HOG algorithm and what
the HOG paper proposes.
Perhaps someone who was involved in programming the HOG-algorithm could answer
my question?

Any help still greatly appreciated,
best regards,
Jan Hendriks

________________________________
From: Long Long Yu <mr.fantastico@...>
To: J H <dahoc3150@...>
Sent: Fri, July 23, 2010 12:56:10 AM
Subject: Re: HOGDescriptor::getDefaultPeopleDetector()

mmm, so, look:

the linear svm try to find N vectors of support machine, so u have N vectors,
but with a linear system ecuations u can get just ONE vector:
score = b + sum (from i=1 to N) of (Y_i .* X) where Y_i is i th of support
vector, and X is the HoG vector... this operation u can write:

score = b + X .* sum (from i=1 to N) of (Y_i) = b + X .* Y, now u have just ONE


support vector, Y... and u have 3780 dimension for the support vector and a
scalar value, b. so 3780 + 1 dimensions

and, i dont know how to get just one HoG vector.... and the dimension is 3780
for every vector... because the window scanner is 128x64 with block of 2 x 2
cells, with cells of 8 x 8 pixels, and with block overlapping of 1 x 1
cell...

________________________________
From: J H <dahoc3150@...>
To: Long Long Yu <mr.fantastico@...>
Cc: OpenCV@yahoogroups.com
Sent: Thu, July 22, 2010 2:08:25 PM
Subject: Re: HOGDescriptor::getDefaultPeopleDetector()

Hi,
thanks for your reply,
so I need to calculate the linear distance between the input feature vector and
the getDefaultPeopleDescriptor() vector, but how do I obtain a vector similar to


the getDefaultPeopleDescriptor() vector from my training data in order to be
able to detect my trained persons? A trained linear SVM usually returns a
separating hyperplane of dimension (inputdimension - 1, that would be 3779 in my


case), or at least the openCV-SVM returns its 440 calculated support vectors of
dimension 3780.
The point I do not understand is how the getDefaultPeopleDescriptor() vector (of


dimension 3780+1) is generated from the training set? I can certainly exclude it


being the center (or the mean vector) of the calculated support vectors. So how
is it generated?

________________________________
From: Long Long Yu <mr.fantastico@...>
To: dahoc3150@...
Sent: Wed, July 21, 2010 8:33:52 PM
Subject: HOGDescriptor::getDefaultPeopleDetector()

because the distance is svm linear (linear support vector machine) and not a
euclidean distance...

________________________________

Hello,
I've currently implemented a people detection algorithm using the Histograms of
Oriented Gradients (HOG) algorithm already present in opencv2. That for I
trained the opencv-internal SVM with positive and negative training samples and


the svm returned 440 support vectors of the correct dimension (3780 for a
window size of 64x128 px).
Now, the hog.setSVMDetector(HOGDescriptor::getDefaultPeopleDetector()); takes
the HOGDescriptor::getDefaultPeopleDetector() vector, which is of size 3780 + 1


(some threshold value I believe) for decision whether there is a person in the
presented image.
My question now is, how can and does the algorithm decide if there is a person
in the image by using the HOGDescriptor::getDefaultPeopleDetector()? How do I
use my trained data to generate such a vector? I tried to calculate the
euclidian distance between the feature vector of the current image and the
getDefaultPeopleDetector vector, but that did not match the person detection
results returned by the getDefaultPeopleDetector. The paper (where HOG is
described) uses the svm decision function, but that is also not the case here,
since then the getDefaultPeopleDetector vector should have different
dimensionality.

Any help greatly appreciated,
best regards,
Jan Hendriks

[Non-text portions of this message have been removed]

[Non-text portions of this message have been removed]







[Non-text portions of this message have been removed]

